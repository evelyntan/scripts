{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a647f5e-43ac-49ae-9428-88eb8d9f3590",
   "metadata": {},
   "source": [
    "# This script extracts words from the csv \n",
    "## to be used to calculate: \n",
    "- words per minute\n",
    "- total words\n",
    "- variance of words across match \n",
    "- variance of words across speakers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17caad44-95ca-4454-ba84-e4c8bcee3cc6",
   "metadata": {},
   "source": [
    "### *function to get cleaned words list per transcript and count the number of words*"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0406d1b5-7097-4411-8cb8-0ddeaaa82f0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_cleaned_words_list(transcript):\n",
    "    import pandas as pd\n",
    "\n",
    "    # import transcript of interest\n",
    "    coded_transcripts_df = pd.read_csv(transcript)\n",
    "\n",
    "    # locate the columns for sentences and players\n",
    "    coded_transcripts_df['Sentence'] = coded_transcripts_df['Sentence'].astype(str)\n",
    "    all_sentences_column = coded_transcripts_df.iloc[:, 3]\n",
    "    players_column = coded_transcripts_df.iloc[:, 0]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_sentences = list(all_sentences_column.values) \n",
    "    players = list(players_column.values)\n",
    "    \n",
    "    # create an empty list to hold all words\n",
    "    all_words = []\n",
    "\n",
    "    # got through each sentence \n",
    "    for sentence in all_sentences:\n",
    "        #print(sentence)\n",
    "        split_the_sentence = sentence.split()\n",
    "\n",
    "        # from each sentence, extract the word\n",
    "        for word in split_the_sentence:\n",
    "            all_words.append(word)\n",
    "\n",
    "    # take out all the '(inaudible)' lines\n",
    "\n",
    "    cleaned_word_list = []\n",
    "\n",
    "    list_with_inaudible_words = [\"(inaudible)\", \"(inaduible\", \"cross\", \"talk)\", \"like\"]\n",
    "    for word in all_words: \n",
    "        if word in list_with_inaudible_words :\n",
    "            continue\n",
    "        else: \n",
    "            cleaned_word_list.append(word)\n",
    "\n",
    "    #print(cleaned_word_list)\n",
    "    \n",
    "    return cleaned_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef7315-2bc5-43f0-9354-543273487eb4",
   "metadata": {},
   "source": [
    "found answer for removing all words that have () and [] from here: https://stackoverflow.com/questions/14596884/remove-text-between-and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2891bf97-4e28-423b-9076-59cde13d9be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      I- I think Gore- Goredrinker's broken on him. ...\n",
       "1      Depends, if you go Goredrinker for late game, ...\n",
       "2      I think this one is going late game but if- if...\n",
       "3      No (inaudible) Goredrinker never tried on this...\n",
       "4      Just for the all-ins you- you have the extra h...\n",
       "                             ...                        \n",
       "143                                                Yeah.\n",
       "144    I just lost my my summoner's, it's fine. Oh okay.\n",
       "145          I still have this- I think- Morg, let's go.\n",
       "146         Bye Teemo. Towers, tower, tower. Uh, Herald.\n",
       "147                        Next stop LEC. GG, good game.\n",
       "Name: Sentence, Length: 148, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_transcript = pd.read_csv('../data/coded-transcripts/recoded-transcripts/team-26.csv')\n",
    "#raw_transcript.head()\n",
    "\n",
    "raw_transcript['Sentence'] = raw_transcript['Sentence'].astype(str)\n",
    "all_sentences = raw_transcript.iloc[:, 3]\n",
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1463c69-a73d-41de-a842-6c917dd0e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all words that have () and [] \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# on mac\n",
    "# raw_transcript = pd.read_csv('../data/coded-transcripts/recoded-transcripts/team-26.csv')\n",
    "# raw_transcript\n",
    "\n",
    "def get_cleaned_words_list(raw_transcript):\n",
    "    # locate the columns for sentences and players\n",
    "    all_sentences_column = raw_transcript.iloc[:, 3]\n",
    "    #raw_transcript['Sentence'] = raw_transcript['Sentence'].astype(str)\n",
    "    #all_sentences_column = raw_transcript.iloc[:, 3]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_sentences = list(all_sentences_column.values) \n",
    "\n",
    "    cleaned_sentences = []\n",
    "    split_sentences = []\n",
    "    cleaned_word_list = []\n",
    "\n",
    "    for sentence in all_sentences: \n",
    "        cleaned_sentences.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", sentence))\n",
    "\n",
    "    for sentence in cleaned_sentences: \n",
    "        split_into_words = sentence.split(' ')\n",
    "        for word in split_into_words:\n",
    "            cleaned_word_list.append(word)\n",
    "    \n",
    "    return cleaned_word_list\n",
    "    \n",
    "\n",
    "#print('Cleaned Sentences', '\\n')\n",
    "#print(cleaned_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1237188-e46e-47af-9305-fa3cf954f8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-',\n",
       " 'I',\n",
       " 'think',\n",
       " 'Gore-',\n",
       " \"Goredrinker's\",\n",
       " 'broken',\n",
       " 'on',\n",
       " 'him.',\n",
       " 'Can',\n",
       " 'try',\n",
       " 'it.',\n",
       " 'Depends,',\n",
       " 'if',\n",
       " 'you',\n",
       " 'go',\n",
       " 'Goredrinker',\n",
       " 'for',\n",
       " 'late',\n",
       " 'game,',\n",
       " 'yes.',\n",
       " 'If-',\n",
       " 'but',\n",
       " 'if',\n",
       " 'you',\n",
       " 'go',\n",
       " 'for',\n",
       " 'picks',\n",
       " 'for',\n",
       " 'early',\n",
       " 'game',\n",
       " 'uh',\n",
       " 'Eclipse-',\n",
       " 'I',\n",
       " 'think',\n",
       " 'this',\n",
       " 'one',\n",
       " 'is',\n",
       " 'going',\n",
       " 'late',\n",
       " 'game',\n",
       " 'but',\n",
       " 'if-',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'Eclipse',\n",
       " 'and',\n",
       " 'try',\n",
       " 'to',\n",
       " 'finish',\n",
       " 'it',\n",
       " 'early',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'o-',\n",
       " 'No',\n",
       " '',\n",
       " 'Goredrinker',\n",
       " 'never',\n",
       " 'tried',\n",
       " 'on',\n",
       " 'this',\n",
       " 'guy',\n",
       " 'but',\n",
       " 'can',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'experience',\n",
       " 'Just',\n",
       " 'for',\n",
       " 'the',\n",
       " 'all-ins',\n",
       " 'you-',\n",
       " 'you',\n",
       " 'have',\n",
       " 'the',\n",
       " 'extra',\n",
       " 'heals',\n",
       " 'which',\n",
       " 'is-',\n",
       " 'Senna',\n",
       " 'and',\n",
       " 'Morgana',\n",
       " 'look',\n",
       " 'good',\n",
       " 'as',\n",
       " 'well',\n",
       " \"they've\",\n",
       " 'both',\n",
       " 'got',\n",
       " 'a',\n",
       " '70%',\n",
       " 'win',\n",
       " 'rate',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'in',\n",
       " 'this',\n",
       " 'queue.',\n",
       " 'Wow,',\n",
       " 'nice.',\n",
       " 'This',\n",
       " 'Morgana-',\n",
       " \"I'm\",\n",
       " 'gonna',\n",
       " 'mute',\n",
       " 'them',\n",
       " '.',\n",
       " 'Alright',\n",
       " 'good',\n",
       " 'luck',\n",
       " 'guys.',\n",
       " \"I'm\",\n",
       " 'heading',\n",
       " 'towards',\n",
       " 'top',\n",
       " 'soon.',\n",
       " 'Yeah',\n",
       " 'you',\n",
       " 'can',\n",
       " 'go,',\n",
       " 'you',\n",
       " 'can',\n",
       " 'come',\n",
       " 'because',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'have',\n",
       " 'an',\n",
       " 'even',\n",
       " 'trade.',\n",
       " 'But',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'stun',\n",
       " 'so.',\n",
       " 'You',\n",
       " 'have',\n",
       " 'a',\n",
       " 'stun',\n",
       " \"that's\",\n",
       " 'okay.',\n",
       " \"I've\",\n",
       " 'ghosted,',\n",
       " 'go.',\n",
       " 'Nice,',\n",
       " 'good',\n",
       " 'job.',\n",
       " \"I'll\",\n",
       " 'let',\n",
       " 'you',\n",
       " 'freeze',\n",
       " 'the',\n",
       " 'wave',\n",
       " 'because',\n",
       " 'he',\n",
       " 'has',\n",
       " 'TP.',\n",
       " 'Yeah.',\n",
       " 'Here',\n",
       " 'he',\n",
       " 'comes',\n",
       " 'again,',\n",
       " 'do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'a',\n",
       " 'second',\n",
       " 'gank?',\n",
       " 'If',\n",
       " 'we',\n",
       " 'kill',\n",
       " 'him',\n",
       " 'here',\n",
       " 'is',\n",
       " 'deleted.',\n",
       " 'Yeah,',\n",
       " 'just',\n",
       " 'give',\n",
       " 'me',\n",
       " 'a',\n",
       " 'sec',\n",
       " 'to',\n",
       " 'clear',\n",
       " 'this.',\n",
       " 'And',\n",
       " \"I'm\",\n",
       " 'close',\n",
       " 'to',\n",
       " 'me-',\n",
       " \"He's\",\n",
       " 'already',\n",
       " 'less',\n",
       " 'than',\n",
       " 'half',\n",
       " 'so',\n",
       " 'E-Q',\n",
       " 'and',\n",
       " \"he's\",\n",
       " 'probably',\n",
       " 'dead.',\n",
       " 'Wait,',\n",
       " 'wait.',\n",
       " 'I',\n",
       " 'messed',\n",
       " 'up,',\n",
       " 'I',\n",
       " 'messed',\n",
       " 'up.',\n",
       " \"It's\",\n",
       " 'cool,',\n",
       " \"it's\",\n",
       " 'cool,',\n",
       " \"it's\",\n",
       " 'fine.',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'worry',\n",
       " 'about.',\n",
       " 'Okay,',\n",
       " 'nice.',\n",
       " 'Teemo',\n",
       " 'is',\n",
       " 'just,',\n",
       " 'just',\n",
       " 'warded',\n",
       " 'but',\n",
       " \"I'm\",\n",
       " 'coming',\n",
       " 'in.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'just',\n",
       " 'reset',\n",
       " 'and',\n",
       " 'TP',\n",
       " 'again?',\n",
       " 'No,',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'TP',\n",
       " 'after.',\n",
       " 'Now',\n",
       " \"you're\",\n",
       " 'dead.',\n",
       " 'Yeah,',\n",
       " 'my',\n",
       " 'bad.',\n",
       " 'My',\n",
       " 'bad.',\n",
       " 'There',\n",
       " 'is',\n",
       " 'no',\n",
       " 'ward',\n",
       " 'nearby.',\n",
       " 'TP.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'flash',\n",
       " 'if',\n",
       " 'needed.',\n",
       " 'Going',\n",
       " 'around.',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'reset.',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " 'Sorry.',\n",
       " 'I',\n",
       " \"can't\",\n",
       " 'rotate.',\n",
       " 'Double',\n",
       " 'kill,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'double',\n",
       " 'kill.',\n",
       " 'Yasuo',\n",
       " 'is',\n",
       " 'behind',\n",
       " 'you.',\n",
       " 'Nice,',\n",
       " 'good',\n",
       " 'flash.',\n",
       " 'Nice,',\n",
       " 'nice.',\n",
       " 'I',\n",
       " 'think',\n",
       " 'I',\n",
       " 'can',\n",
       " 'kill',\n",
       " 'him.',\n",
       " 'No',\n",
       " 'no,',\n",
       " \"you're\",\n",
       " 'alone.',\n",
       " 'Take',\n",
       " 'your',\n",
       " 'advantage',\n",
       " 'yeah,',\n",
       " 'go',\n",
       " 'back,',\n",
       " 'spend',\n",
       " 'your',\n",
       " 'gold.',\n",
       " 'Yeah',\n",
       " 'and',\n",
       " 'he',\n",
       " 'has',\n",
       " 'vision',\n",
       " 'over',\n",
       " 'there',\n",
       " 'too',\n",
       " 'and',\n",
       " \"I'm\",\n",
       " 'not',\n",
       " 'coming',\n",
       " 'top',\n",
       " 'side',\n",
       " 'yet.',\n",
       " 'I',\n",
       " 'think',\n",
       " 'I',\n",
       " 'catch',\n",
       " 'Yi',\n",
       " 'here.',\n",
       " 'Byeee.',\n",
       " 'Yup',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " 'Good',\n",
       " 'job.',\n",
       " 'Nice.',\n",
       " 'I',\n",
       " 'will',\n",
       " 'start',\n",
       " 'running,',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ulti.',\n",
       " 'I',\n",
       " 'have',\n",
       " '6.',\n",
       " 'And',\n",
       " 'then',\n",
       " 'wait',\n",
       " 'a',\n",
       " 'bit',\n",
       " \"I'm\",\n",
       " 'going',\n",
       " 'mid.',\n",
       " \"I'm\",\n",
       " 'second',\n",
       " 'tower.',\n",
       " 'Not',\n",
       " 'yet',\n",
       " 'there.',\n",
       " 'Going',\n",
       " 'to',\n",
       " 'here',\n",
       " 'in',\n",
       " 'five,',\n",
       " 'four,',\n",
       " 'three,',\n",
       " 'two,',\n",
       " 'going.',\n",
       " 'Nice',\n",
       " 'guys,',\n",
       " 'nice.',\n",
       " 'Nice',\n",
       " 'ult,',\n",
       " 'well',\n",
       " 'played.',\n",
       " 'Nice.',\n",
       " 'Bot',\n",
       " 'lane',\n",
       " 'got',\n",
       " 'kill.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'can',\n",
       " 'crash',\n",
       " 'the',\n",
       " 'wave',\n",
       " 'and',\n",
       " 'eh',\n",
       " 'so',\n",
       " 'I',\n",
       " 'can',\n",
       " 'gank',\n",
       " 'mid',\n",
       " 'again.',\n",
       " 'Yeah,',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'reset',\n",
       " 'anyway.',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'need',\n",
       " 'help',\n",
       " 'clearing?',\n",
       " 'Eh,',\n",
       " 'should',\n",
       " 'be',\n",
       " 'okay.',\n",
       " 'Just',\n",
       " 'about',\n",
       " 'crashed.',\n",
       " \"He's\",\n",
       " 'blinding',\n",
       " 'my',\n",
       " 'stun.',\n",
       " \"It's\",\n",
       " 'not',\n",
       " 'usual.',\n",
       " 'I',\n",
       " \"can't\",\n",
       " 'see',\n",
       " 'a',\n",
       " 'Teemo',\n",
       " 'who',\n",
       " 'can',\n",
       " 'do',\n",
       " 'that.',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'have',\n",
       " 'ult',\n",
       " 'for',\n",
       " 'another',\n",
       " '35',\n",
       " 'seconds.',\n",
       " 'Where',\n",
       " 'is',\n",
       " 'Teemo?',\n",
       " 'He',\n",
       " 'went',\n",
       " 'B',\n",
       " 'he',\n",
       " 'was',\n",
       " '40',\n",
       " 'life.',\n",
       " 'But',\n",
       " 'like-',\n",
       " 'like',\n",
       " 'I',\n",
       " 'said',\n",
       " \"I'm\",\n",
       " 'doing',\n",
       " 'Goredrinker,',\n",
       " 'but',\n",
       " 'if',\n",
       " 'I',\n",
       " 'run',\n",
       " 'it',\n",
       " 'for',\n",
       " 'Eclipse',\n",
       " 'I',\n",
       " 'probably',\n",
       " 'would',\n",
       " 'kill',\n",
       " 'him',\n",
       " 'there.',\n",
       " 'Oh,',\n",
       " 'you',\n",
       " 'can',\n",
       " 'go',\n",
       " 'for',\n",
       " 'Eclipse.',\n",
       " 'Nah',\n",
       " 'but',\n",
       " '-',\n",
       " 'but',\n",
       " \"I'm\",\n",
       " 'really',\n",
       " 'trying.',\n",
       " \"It's\",\n",
       " 'uh',\n",
       " 'it,',\n",
       " 'it',\n",
       " 'really',\n",
       " 'needs.',\n",
       " 'Uh',\n",
       " 'the',\n",
       " 'late',\n",
       " 'game',\n",
       " 'the,',\n",
       " 'in',\n",
       " 'the',\n",
       " '',\n",
       " 'Yasuo',\n",
       " 'has',\n",
       " 'shoved',\n",
       " 'the',\n",
       " 'wave.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ult.',\n",
       " 'But',\n",
       " 'just',\n",
       " 'let',\n",
       " 'me',\n",
       " 'take-.',\n",
       " 'Wait,',\n",
       " 'wait,',\n",
       " 'let',\n",
       " 'me,',\n",
       " 'let',\n",
       " 'me',\n",
       " 'take',\n",
       " 'wraiths.',\n",
       " 'The',\n",
       " 'golem,',\n",
       " 'since',\n",
       " \"I'm\",\n",
       " 'already',\n",
       " 'here.',\n",
       " 'This',\n",
       " 'will',\n",
       " 'give',\n",
       " 'me',\n",
       " 'the',\n",
       " 'smite.',\n",
       " \"I'm\",\n",
       " 'coming.',\n",
       " 'Go.',\n",
       " 'Nice,',\n",
       " 'well',\n",
       " 'played.',\n",
       " 'Master',\n",
       " 'Yi,',\n",
       " 'Master',\n",
       " 'Yi,',\n",
       " 'Master',\n",
       " 'Yi.',\n",
       " 'Whereabouts?',\n",
       " 'Nice,',\n",
       " 'nice,',\n",
       " 'we',\n",
       " 'won,',\n",
       " 'we',\n",
       " 'won.',\n",
       " 'Good',\n",
       " 'job.',\n",
       " 'I',\n",
       " 'got',\n",
       " 'two',\n",
       " 'plates',\n",
       " 'there.',\n",
       " 'Nice',\n",
       " 'nice.',\n",
       " 'And',\n",
       " 'Teemo',\n",
       " 'flash',\n",
       " 'there.',\n",
       " \"I'm\",\n",
       " 'gonna',\n",
       " 'reset.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ulti',\n",
       " 'so',\n",
       " 'I',\n",
       " 'think',\n",
       " \"I'll\",\n",
       " 'run',\n",
       " 'down',\n",
       " 'mid',\n",
       " 'again.',\n",
       " 'Okay,',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'time,',\n",
       " 'I',\n",
       " 'have',\n",
       " 'red',\n",
       " 'smite.',\n",
       " 'Okay.',\n",
       " \"He's\",\n",
       " 'dead.',\n",
       " \"I'm\",\n",
       " 'just',\n",
       " 'gonna',\n",
       " 'do',\n",
       " 'this,',\n",
       " 'herald.',\n",
       " \"I'm\",\n",
       " 'just',\n",
       " 'gonna',\n",
       " 'ward',\n",
       " 'then.',\n",
       " 'They',\n",
       " 'think',\n",
       " \"we've-\",\n",
       " 'Place',\n",
       " 'it',\n",
       " 'mid',\n",
       " 'if',\n",
       " 'you',\n",
       " 'wanna',\n",
       " 'guys',\n",
       " 'play',\n",
       " 'another,',\n",
       " 'another',\n",
       " 'time',\n",
       " 'mid.',\n",
       " \"Yasuo's\",\n",
       " 'here.',\n",
       " 'He',\n",
       " 'is',\n",
       " 'here.',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " 'Shit,',\n",
       " 'Yi',\n",
       " 'made',\n",
       " 'it',\n",
       " 'away.',\n",
       " \"I'm\",\n",
       " 'dead.',\n",
       " 'Nice.',\n",
       " 'Nice.',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'even',\n",
       " 'know',\n",
       " 'where',\n",
       " 'to',\n",
       " 'take',\n",
       " 'that',\n",
       " 'off',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'these',\n",
       " 'cool',\n",
       " 'things',\n",
       " 'he',\n",
       " 'had.',\n",
       " 'Yeah',\n",
       " 'they',\n",
       " 'e-',\n",
       " 'they',\n",
       " 'e-eating.',\n",
       " 'So',\n",
       " \"I'm\",\n",
       " 'gonna',\n",
       " 'run-',\n",
       " 'Nice',\n",
       " 'now',\n",
       " 'you',\n",
       " 'can',\n",
       " 'just',\n",
       " 'kill',\n",
       " 'him.',\n",
       " 'I',\n",
       " 'will',\n",
       " 'run',\n",
       " 'bot',\n",
       " 'now',\n",
       " 'with',\n",
       " 'my',\n",
       " 'ulti,',\n",
       " 'I',\n",
       " 'have',\n",
       " 'TP',\n",
       " 'if',\n",
       " 'needed.',\n",
       " 'So-',\n",
       " 's',\n",
       " \"They're\",\n",
       " 'engaging.',\n",
       " \"They're\",\n",
       " 'dying.',\n",
       " 'Which',\n",
       " 'is',\n",
       " 'different.',\n",
       " '',\n",
       " 'Go,',\n",
       " 'go,',\n",
       " 'go.',\n",
       " 'No',\n",
       " \"I'm\",\n",
       " 'not',\n",
       " 'in',\n",
       " 'range',\n",
       " 'yet.',\n",
       " 'Oh',\n",
       " 'I',\n",
       " 'lived,',\n",
       " 'no',\n",
       " 'way.',\n",
       " 'That',\n",
       " 'was',\n",
       " 'close.',\n",
       " 'Okay,',\n",
       " 'so',\n",
       " \"I'm\",\n",
       " 'think',\n",
       " \"I'm\",\n",
       " 'tower-diving',\n",
       " 'him.',\n",
       " 'I',\n",
       " 'think',\n",
       " 'I',\n",
       " 'can',\n",
       " 'kill',\n",
       " 'him',\n",
       " 'with',\n",
       " 'Q',\n",
       " 'if',\n",
       " 'needed.',\n",
       " \"I'm\",\n",
       " 'not.',\n",
       " 'Close.',\n",
       " 'Okay.',\n",
       " \"I'll\",\n",
       " 'just',\n",
       " 'put',\n",
       " 'this',\n",
       " 'here.',\n",
       " \"Let's\",\n",
       " 'take',\n",
       " 'tower',\n",
       " 'since',\n",
       " \"you're\",\n",
       " 'already',\n",
       " 'here.',\n",
       " 'Yes,',\n",
       " 'sure.',\n",
       " \"Let's,\",\n",
       " \"l-let's\",\n",
       " 'go',\n",
       " 'on.',\n",
       " 'Yes.',\n",
       " 'I',\n",
       " 'go',\n",
       " 'B',\n",
       " 'and',\n",
       " 'TP',\n",
       " 'top.',\n",
       " 'Yeah.',\n",
       " \"I'm\",\n",
       " 'coming',\n",
       " 'mid.',\n",
       " 'Okay.',\n",
       " \"Let's\",\n",
       " 'go.',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'rotate',\n",
       " 'to',\n",
       " 'a',\n",
       " 'side',\n",
       " 'lane,',\n",
       " 'if',\n",
       " 'bot',\n",
       " \"lane's\",\n",
       " 'over.',\n",
       " 'I',\n",
       " 'made',\n",
       " 'it',\n",
       " 'out.',\n",
       " 'I',\n",
       " 'made',\n",
       " 'it',\n",
       " 'out.',\n",
       " 'Fuck,',\n",
       " 'what',\n",
       " 'the',\n",
       " 'fuck',\n",
       " 'he',\n",
       " 'ignited',\n",
       " 'me.',\n",
       " 'Nice,',\n",
       " 'nice.',\n",
       " 'Nice.',\n",
       " 'We',\n",
       " 'still',\n",
       " 'fuck',\n",
       " 'everything.',\n",
       " 'I',\n",
       " 'will',\n",
       " 'catch',\n",
       " 'up',\n",
       " 'on',\n",
       " 'farm',\n",
       " 'now.',\n",
       " 'You',\n",
       " 'dead.',\n",
       " 'Ah!',\n",
       " '.',\n",
       " 'What',\n",
       " 'was',\n",
       " 'that',\n",
       " 'Ah!',\n",
       " 'Panic.',\n",
       " 'Oh,',\n",
       " 'oh',\n",
       " 'nice.',\n",
       " \"You're\",\n",
       " 'so',\n",
       " 'lucky.',\n",
       " 'Yeah.',\n",
       " '',\n",
       " 'saving',\n",
       " 'lives',\n",
       " 'yeah.',\n",
       " 'Yi',\n",
       " 'is',\n",
       " 'coming',\n",
       " 'top,',\n",
       " \"I'm\",\n",
       " 'falling',\n",
       " 'back',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ulti',\n",
       " 'so',\n",
       " 'if',\n",
       " 'I',\n",
       " 'go',\n",
       " 'mid',\n",
       " 'again.',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'rotate',\n",
       " 'I',\n",
       " \"shouldn't\",\n",
       " 'be',\n",
       " 'in',\n",
       " 'in',\n",
       " 'mid',\n",
       " 'now.',\n",
       " 'Okay,',\n",
       " 'going',\n",
       " 'to',\n",
       " 'ult,',\n",
       " 'since',\n",
       " 'Morgana',\n",
       " 'enter.',\n",
       " 'Nice,',\n",
       " 'you',\n",
       " 'guys',\n",
       " 'got',\n",
       " 'that.',\n",
       " \"It's\",\n",
       " 'a',\n",
       " 'free',\n",
       " 'game',\n",
       " 'now',\n",
       " 'I',\n",
       " 'think.',\n",
       " 'Yeah,',\n",
       " 'he-',\n",
       " 'he',\n",
       " 'ignited',\n",
       " 'me.',\n",
       " 'Teemo',\n",
       " 'is',\n",
       " 'here',\n",
       " 'top.',\n",
       " 'Drake',\n",
       " 'in',\n",
       " '15.',\n",
       " 'Okay.',\n",
       " 'Heading',\n",
       " 'towards',\n",
       " 'Drake.',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'have',\n",
       " 'ult',\n",
       " 'or',\n",
       " 'TP',\n",
       " 'but',\n",
       " 'I',\n",
       " 'can',\n",
       " 'fall',\n",
       " 'back.',\n",
       " 'I',\n",
       " \"won't\",\n",
       " 'take',\n",
       " 'the',\n",
       " 'tower',\n",
       " 'yet.',\n",
       " \"Let's\",\n",
       " 'kill',\n",
       " 'Sett.',\n",
       " 'Nice,',\n",
       " 'well',\n",
       " 'played.',\n",
       " 'Nice.',\n",
       " 'Take',\n",
       " 'Drake',\n",
       " 'they',\n",
       " 'push',\n",
       " 'top.',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'you,',\n",
       " 'I',\n",
       " 'thought',\n",
       " 'you',\n",
       " 'take',\n",
       " 'some',\n",
       " 'of',\n",
       " 'these.',\n",
       " 'Oh',\n",
       " 'Yasuo,',\n",
       " 'what',\n",
       " 'the',\n",
       " 'fuck?',\n",
       " 'How',\n",
       " 'dare',\n",
       " 'he.',\n",
       " \"He's\",\n",
       " 'dogshit,',\n",
       " \"he's\",\n",
       " 'dogshit.',\n",
       " 'Okay',\n",
       " 'so',\n",
       " 'I',\n",
       " 'can',\n",
       " 'delete',\n",
       " 'Teemo',\n",
       " 'now',\n",
       " 'so-',\n",
       " \"Fuckin'\",\n",
       " 'smurfing',\n",
       " 'on',\n",
       " 'Teemo',\n",
       " 'there',\n",
       " 'mate.',\n",
       " 'Look',\n",
       " '',\n",
       " 'at',\n",
       " 'him.',\n",
       " 'Dogshit.',\n",
       " 'Herald',\n",
       " 'is',\n",
       " 'up.',\n",
       " 'I',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'finish',\n",
       " 'this',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'jungle',\n",
       " 'and',\n",
       " 'reset,',\n",
       " 'just',\n",
       " 'a',\n",
       " 'sec.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'start',\n",
       " 'it',\n",
       " 'anyway.',\n",
       " 'Even',\n",
       " 'if',\n",
       " 'he',\n",
       " 'comes',\n",
       " 'I',\n",
       " 'can',\n",
       " 'kill',\n",
       " 'him.',\n",
       " 'Okay.',\n",
       " 'So',\n",
       " 'we',\n",
       " 'pop',\n",
       " 'up',\n",
       " 'the',\n",
       " 'planter.',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_transcript = pd.read_csv('../data/coded-transcripts/recoded-transcripts/team-26.csv')\n",
    "\n",
    "cleaned_words_list = get_cleaned_words_list(raw_transcript)\n",
    "\n",
    "cleaned_words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312fe62-b08e-4e62-874a-fbfcfee13048",
   "metadata": {},
   "source": [
    "### *function to get team number*"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ee82440-5c32-4b29-a72b-fbc2bb4bc165",
   "metadata": {},
   "source": [
    "# only works for windows file names\n",
    "def get_team_number_from_csv(transcript):\n",
    "\n",
    "    split_file_name_into_content = transcript.split(\"\\\\\")\n",
    "    #print(split_file_name_into_content)\n",
    "    team_number_file_name = split_file_name_into_content[6][:-4]\n",
    "    #print(team_number_file_name)\n",
    "    split = team_number_file_name.split(\"-\")\n",
    "\n",
    "    team_number = split[1]\n",
    "   \n",
    "    return team_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e5d772-5c0b-43a1-bace-5083c85b168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code works on Mac only\n",
    "# make cell raw if not using\n",
    "\n",
    "def get_team_number_from_csv(transcript):\n",
    "\n",
    "    split_1 = transcript.split('/')\n",
    "    split_2 = split_1[8][:-4].split('-')\n",
    "    team_number = split_2[1]\n",
    "   \n",
    "    return team_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418e578-6fc1-4f49-ab3c-aa7fb24924c3",
   "metadata": {},
   "source": [
    "### *import the team log csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23786ecf-10de-4683-8121-2cc7d75f7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log_of_team_data_df = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\log-of-team-data.csv')\n",
    "log_of_team_data_df.head()\n",
    "print(log_of_team_data_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c0618-f704-4865-8016-8d145ca5e8b0",
   "metadata": {},
   "source": [
    "### *run the functions over all the cleaned transcripts and merge output with team log*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9d373e-7aff-4a5c-a844-6a6e41fa2098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/coded-transcripts/recoded-transcripts/team-2.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w8/b937dpk969g502kmx14tg5sc0000gp/T/ipykernel_56344/1408441852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# get the cleaned words list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcleaned_word_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cleaned_words_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# count the total number of cleaned words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w8/b937dpk969g502kmx14tg5sc0000gp/T/ipykernel_56344/3159618956.py\u001b[0m in \u001b[0;36mget_cleaned_words_list\u001b[0;34m(raw_transcript)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cleaned_words_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_transcript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# locate the columns for sentences and players\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mall_sentences_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_transcript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#raw_transcript['Sentence'] = raw_transcript['Sentence'].astype(str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#all_sentences_column = raw_transcript.iloc[:, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# go through the files in the directory\n",
    "# transcripts_windows = glob.glob(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\*.csv')\n",
    "\n",
    "transcripts = glob.glob('../data/coded-transcripts/recoded-transcripts/*.csv')\n",
    "\n",
    "#print('Files in folder:',transcripts)\n",
    "#print(\"\")\n",
    "team_num_and_total_words_dict = {'team_number': [], 'total_words': []}\n",
    "\n",
    "# loop over each transcript\n",
    "for transcript in transcripts: \n",
    "    print(transcript)\n",
    "    \n",
    "    # get the cleaned words list\n",
    "    cleaned_word_list = get_cleaned_words_list(transcript)\n",
    "    \n",
    "    # count the total number of cleaned words\n",
    "    total_cleaned_words = len(cleaned_word_list)\n",
    "    \n",
    "    # add the total number of cleaned words to the dictionary\n",
    "    team_num_and_total_words_dict['total_words'].append(total_cleaned_words)\n",
    "    \n",
    "    # then get the corresponding team number\n",
    "    team_number = get_team_number_from_csv(transcript)\n",
    "    #print(team_number)\n",
    "    \n",
    "    # and add the corresponding team number to the dictionary\n",
    "    team_num_and_total_words_dict['team_number'].append(int(team_number))\n",
    "\n",
    "\n",
    "    print('total words = ', total_cleaned_words)\n",
    "    print(\"\")\n",
    "\n",
    "team_num_and_total_words_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28eeb28-d49c-46f7-95e0-e032fd287053",
   "metadata": {},
   "source": [
    "convert dictionary with team number and total words to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbbd15-344c-4e2f-9c8b-6efba31f0d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the dictionary to dataframe\n",
    "team_num_and_total_words_df = pd.DataFrame.from_dict(team_num_and_total_words_dict)\n",
    "\n",
    "team_num_and_total_words_df\n",
    "#print(team_num_and_total_words_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61841c-1a99-4d53-be21-22e33d6d85fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the dataframes on the team_number column \n",
    "merged_df = pd.merge(log_of_team_data_df, team_num_and_total_words_df, on = 'team_number')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544213e-a344-4060-9465-5e0ffa8b800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd32c69-67f7-4f03-b7db-dba0b42230e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3589f229-1c9c-41c6-8a64-1184ced10c99",
   "metadata": {},
   "source": [
    "## this block converts minutes and seconds to seconds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11833b64-1f63-493f-ab61-e4c5ff09ca49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# convert match duration from minutes and seconds to seconds\n",
    "from datetime import timedelta\n",
    "\n",
    "def seconder(x):\n",
    "    mins, secs = map(float, x.split(':'))\n",
    "    td = timedelta(minutes=mins, seconds=secs)\n",
    "    return td.total_seconds()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0aefc68-edda-4ad5-a9b8-e8a19c2a6846",
   "metadata": {},
   "source": [
    "def get_minute_index(df_of_transcript):\n",
    "    # ensure timestamp as date time\n",
    "    transcript['Timestamp'] = transcript['Timestamp'].apply(seconder)\n",
    "    \n",
    "    # get minute index for match duration:\n",
    "\n",
    "    # first convert timestamp to int\n",
    "    transcript['minute_index'] = transcript['Timestamp'].astype(int)\n",
    "\n",
    "    # turn the timestamp into datetime object\n",
    "    transcript['time_object'] = pd.to_datetime(transcript['minute_index'], unit = 's')\n",
    "\n",
    "    # get only the minutes from the datetime object\n",
    "    transcript['minute_index'] = transcript['time_object'].dt.minute\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c307b-7acc-404c-9a88-9cfd97ac96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minute_index(transcript):\n",
    "    # get a correctly formatted timeobject (ignore date output)\n",
    "    transcript['time_object'] = pd.to_datetime(transcript['Timestamp'], format = '%M:%S:%f')\n",
    "\n",
    "    # get only the minutes from the datetime object\n",
    "    transcript['minute_index'] = transcript['time_object'].dt.minute\n",
    "    \n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e58f8-a393-4b3c-b23e-2626be83d6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "transcript = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\team-22.csv')\n",
    "transcript.head()\n",
    "\n",
    "get_minute_index(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7c4df-be5b-48ba-8180-a2b5cb065dd2",
   "metadata": {},
   "source": [
    "## Function to extract single words for wpm calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1ef2c-d53a-431c-a45c-de3036a114b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cleaned_words(coded_transcripts_df):\n",
    "\n",
    "    # locate the columns for sentences and players\n",
    "    all_sentences_column = coded_transcripts_df.iloc[:, 3]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_sentences = list(all_sentences_column.values) \n",
    "    \n",
    "    # create an empty list to hold all words\n",
    "    all_words = []\n",
    "\n",
    "    # got through each sentence \n",
    "    for sentence in all_sentences:\n",
    "        split_the_sentence = sentence.split()\n",
    "\n",
    "        # from each sentence, extract the word\n",
    "        for word in split_the_sentence:\n",
    "            all_words.append(word)\n",
    "\n",
    "    # take out all the '(inaudible)' lines\n",
    "\n",
    "    cleaned_word_list = []\n",
    "\n",
    "    list_with_inaudible_words = [\"(inaudible)\", \"(inaduible\", \"cross\", \"talk)\", \"like\"]\n",
    "    for word in all_words: \n",
    "        if word in list_with_inaudible_words :\n",
    "            continue\n",
    "        else: \n",
    "            cleaned_word_list.append(word)\n",
    "\n",
    "    #print(cleaned_word_list)\n",
    "    \n",
    "    return len(cleaned_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7f811-4c52-4001-816f-5983bcd0e09b",
   "metadata": {},
   "source": [
    "## Function to get word utterances each minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d59c7f-c013-47ae-9c75-723549e11ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_words_each_minute(transcript):\n",
    "    # get unique minute indexes\n",
    "    # for each row of that minute index, get the number of words\n",
    "    # that's the number of words per minute\n",
    "\n",
    "    unique_minutes =  pd.unique(transcript['minute_index'])\n",
    "\n",
    "    words_each_minute = []\n",
    "\n",
    "    for minute in range(max(unique_minutes) + 1):\n",
    "        sentences_this_minute = transcript[transcript['minute_index'] == minute]\n",
    "\n",
    "        number_of_words_in_minute_index = extract_cleaned_words(sentences_this_minute)\n",
    "\n",
    "        words_each_minute.append(number_of_words_in_minute_index)\n",
    "\n",
    "\n",
    "    #print(\"unique minutes: \", unique_minutes)\n",
    "\n",
    "    #print('words each minute:', words_each_minute)\n",
    "\n",
    "    # returns a list of total word utterance each minute\n",
    "    return words_each_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266d646-612a-4f30-a8cc-0b318bf269bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96b987-ae75-4a72-82cf-c078f7f1da08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442ebe9-0423-4c09-b70e-21e4c12242dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aeef7a1-9344-4671-bca0-3f74ab900856",
   "metadata": {},
   "source": [
    "## Descriptive Analysis Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8fdad-dc39-4b5f-a042-56ec662726f4",
   "metadata": {},
   "source": [
    "this function gets the descriptive stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3eeb15-a5ec-4e2d-91f1-e1d34b9b275e",
   "metadata": {},
   "source": [
    "Within team variables: \n",
    " - mean wpm : rate of chat\n",
    " - variance wpm : distribution of chat across match duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a28cb6-1f5a-4eb9-b4a5-6f255e794eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_descriptive_stats_for_words(count_of_words_each_minute):\n",
    "    # get descriptive stats\n",
    "\n",
    "    # get the stats and add stats as element to list\n",
    "    get_mean_wpm = np.mean(count_of_words_each_minute)\n",
    "    \n",
    "    get_variance_wpm = np.var(count_of_words_each_minute)\n",
    "    \n",
    "    get_sum_wpm = np.sum(count_of_words_each_minute)\n",
    "\n",
    "    get_median_wpm = np.median(count_of_words_each_minute)\n",
    "\n",
    "    #print('mean:', mean_wpm)\n",
    "    #print('variance:', variance_wpm)\n",
    "    #print('sum:', sum_wpm)\n",
    "    #print('median:', median_wpm)\n",
    "    \n",
    "    return get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1a6da-e31d-4f4f-9b2c-fd8f9ff722c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ad840-bc72-49f2-8404-282d762ff118",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRYING TO RUN IT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4082c97f-a886-441e-b092-ee485767af28",
   "metadata": {
    "tags": []
   },
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "transcript = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\team-22.csv')\n",
    "\n",
    "# first convert to minute index\n",
    "get_minute_index(transcript)\n",
    "\n",
    "# get word utterance each minute\n",
    "words_each_minute = get_words_each_minute(transcript)\n",
    "\n",
    "# then get the code utterance each minute\n",
    "#get_code_utterance_each_minute(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33c1cb57-21f7-4617-8b63-1bff1b558df0",
   "metadata": {},
   "source": [
    "# populate the descriptives\n",
    "team_number = []\n",
    "mean_wpm = []\n",
    "variance_wpm = []\n",
    "sum_wpm = []\n",
    "median_wpm = []\n",
    "\n",
    "# then get descriptives\n",
    "get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm = get_descriptive_stats_for_words(words_each_minute)\n",
    "\n",
    "mean_wpm.append(get_mean_wpm)\n",
    "variance_wpm.append(get_variance_wpm)\n",
    "sum_wpm.append(get_sum_wpm)\n",
    "median_wpm.append(get_median_wpm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd332753-0371-4351-a1b0-26cd0bf75683",
   "metadata": {},
   "source": [
    "print(team_number, mean_wpm, variance_wpm, sum_wpm, median_wpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c3023-d316-4c24-8eff-e32691ad5cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5300a833-c8fd-4b08-aaf0-93b56a1d5120",
   "metadata": {},
   "source": [
    "This section runs all the functions to get descriptive stats for word utterances\n",
    "----------------\n",
    "\n",
    "to do: \n",
    "- merge with the log of team data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cea94e-a45d-4e0e-8689-3a17012d79e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# populate the descriptives\n",
    "team_number = []\n",
    "mean_wpm = []\n",
    "variance_wpm = []\n",
    "sum_words = []\n",
    "median_wpm = []\n",
    "\n",
    "# go through the files in the directory\n",
    "transcripts = glob.glob(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\*.csv')\n",
    "\n",
    "#get_team_number_from_xls(transcripts)\n",
    "for transcript in transcripts: \n",
    "    print(transcript)\n",
    "\n",
    "    # get team number\n",
    "    team_number.append(int(get_team_number_from_csv(transcript)))\n",
    "    \n",
    "    # read the transcript as a dataframe\n",
    "    transcript = pd.read_csv(transcript)\n",
    "\n",
    "    #transcript.head()\n",
    "\n",
    "    # first convert to minute index\n",
    "    get_minute_index(transcript)\n",
    "\n",
    "    # then get the word utterance each minute\n",
    "    words_each_minute = get_words_each_minute(transcript)\n",
    "\n",
    "    # then get descriptives\n",
    "    get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm = get_descriptive_stats_for_words(words_each_minute)\n",
    "\n",
    "    mean_wpm.append(get_mean_wpm)\n",
    "    variance_wpm.append(get_variance_wpm)\n",
    "    sum_words.append(get_sum_wpm)\n",
    "    median_wpm.append(get_median_wpm)\n",
    "\n",
    "print(team_number, mean_wpm, variance_wpm, sum_words, median_wpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104298f-5f4c-4e92-a009-e94ff9367194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050253bd-6748-48ed-b247-a3ae40869737",
   "metadata": {},
   "source": [
    "create a dataframe of descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8e87e-27e7-4844-99f6-becc41eff429",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives = {'team_number': team_number, 'mean_wpm': mean_wpm, 'variance_wpm': variance_wpm, 'sum_words': sum_words, 'median_wpm': median_wpm}\n",
    "\n",
    "descriptives_df = pd.DataFrame(descriptives)\n",
    "\n",
    "descriptives_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84350f89-2116-4401-a83e-d2c101faf6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the dataframes on the team_number column \n",
    "log_with_descriptives = pd.merge(log_of_team_data_df, descriptives_df, on = 'team_number')\n",
    "\n",
    "log_with_descriptives\n",
    "\n",
    "# uncomment to save to csv\n",
    "#log_with_descriptives.to_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\log_with_descriptives.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cf2c1-c225-4702-b147-502d98176b29",
   "metadata": {},
   "source": [
    "## This section gets descriptive stats for code utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60058784-ba0a-49c3-b350-28f68e343b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4244fc3-5943-4349-9f96-3f0828428e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opinions\n",
    "# then get descriptives\n",
    "get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm = get_descriptive_stats_for_words(words_each_minute)\n",
    "\n",
    "# append to corresponding list\n",
    "opinion_mean_upm = []\n",
    "opinion_variance_upm = []\n",
    "opinion_sum = []\n",
    "opinion_median_upm = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78438ca3-4238-42a2-8c4f-019bcf5e8eaa",
   "metadata": {},
   "source": [
    "### to do: \n",
    "- get speaker distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f338a-47e9-4ad2-813b-ee7c5f38fedc",
   "metadata": {},
   "source": [
    "get speaker distribution\n",
    "- step 1: get total words per player per team\n",
    "- step 2: calculate variance of words per player per team"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49a78656-13f9-4dfb-a807-879d168e10de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a769356a-e558-4d1a-a69c-e52c203b9403",
   "metadata": {},
   "source": [
    "######### Cells in this section are to remind you of the steps you took to create the function ##########"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71ca34f9-5906-4aea-ae5c-dc3104aec0ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# create an empty list to hold all words\n",
    "all_words = []\n",
    "\n",
    "# got through each sentence \n",
    "for sentence in all_sentences:\n",
    "    split_the_sentence = sentence.split()\n",
    "    \n",
    "    # from each sentence, extract the word\n",
    "    for word in split_the_sentence:\n",
    "        all_words.append(word)\n",
    "\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6e8a686-b0a4-47e0-a458-be5c6511fc65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# take out all the '(inaudible)' lines\n",
    "\n",
    "cleaned_word_list = []\n",
    "\n",
    "list_with_inaudible_words = [\"(inaudible)\", \"(inaduible\", \"cross\", \"talk)\", \"like\"]\n",
    "for word in all_words: \n",
    "    if word in list_with_inaudible_words :\n",
    "        continue\n",
    "    else: \n",
    "        cleaned_word_list.append(word)\n",
    "\n",
    "        \n",
    "print(cleaned_word_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a1e89f8-40ad-4aea-bbe1-5652081817e0",
   "metadata": {},
   "source": [
    "# get mean words per minute per team \n",
    "def mean_words_per_second(merged_df): \n",
    "    pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "    \n",
    "    merged_df['mean_wpm'] = merged_df['total_words']/(merged_df['match_duration_in_seconds']/60)\n",
    "    \n",
    "    return merged_df\n",
    "    # needs to look like: \n",
    "    # total_words/(match_duration_in_seconds / 60)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd46cd33-3719-4955-a1dd-bb95c4889ccc",
   "metadata": {},
   "source": [
    "df_with_mean_wpm = mean_words_per_second(merged_df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2138b78a-9982-4968-8517-9558772ed1e4",
   "metadata": {},
   "source": [
    "######### Cells in this section are to remind you of the steps you took to create the function ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1c014-7f89-4d30-9760-ef91996f1a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0fe20cff-b794-4c16-ae55-8544c2789401",
   "metadata": {},
   "source": [
    "# get the category column\n",
    "    code_column = transcript.iloc[:, 8]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_codes = list(code_column.values) \n",
    "\n",
    "    unique_minutes =  pd.unique(transcript['minute_index'])\n",
    "\n",
    "    # create empty lists to hold counts of each category per minute\n",
    "    commands_each_minute = []\n",
    "    suggestions_each_minute = []\n",
    "    opinions_each_minute = []\n",
    "    observations_each_minute = []\n",
    "    questions_each_minute = []\n",
    "    answers_each_minute = []\n",
    "    agrees_each_minute = []\n",
    "    disagrees_each_minute = []\n",
    "    sharings_each_minute = []\n",
    "    emotions_each_minute = []\n",
    "    encourages_each_minute = []\n",
    "    nontasks_each_minute = []\n",
    "    frustrations_each_minute = []\n",
    "    humours_each_minute = []\n",
    "    apologies_each_minute = []\n",
    "    thanks_each_minute = []\n",
    "    miscs_each_minute = []\n",
    "    \n",
    "    # create an empty list to hold all codes\n",
    "    command = []\n",
    "    suggestion = []\n",
    "    opinion_analysis = []\n",
    "    observation = []\n",
    "    question = []\n",
    "    answer = []\n",
    "    agree_acknowledge = []\n",
    "    disagree = []\n",
    "    sharing_intention = []\n",
    "    emotional_expression = []\n",
    "    encouragement = []\n",
    "    non_task = []\n",
    "    frustration = []\n",
    "    humour_taunting = []\n",
    "    apologies_remorse = []\n",
    "    thanks_welcome = []\n",
    "    misc = []\n",
    "\n",
    "    # extract the category counts per minute\n",
    "\n",
    "    for minute in range(max(unique_minutes) + 1):\n",
    "        codes_this_minute = transcript[transcript['minute_index'] == minute]\n",
    "\n",
    "        for code in codes_this_minute['rater1_1']:\n",
    "\n",
    "            if code == 'misc': \n",
    "                misc.append(code)\n",
    "\n",
    "            if code == 'command': \n",
    "                command.append(code)\n",
    "\n",
    "            if code == 'observation': \n",
    "                observation.append(code)\n",
    "\n",
    "            if code == 'suggestion': \n",
    "                suggestion.append(code)\n",
    "\n",
    "            if code == 'question or inquiry': \n",
    "                question.append(code)\n",
    "\n",
    "            if code == 'answer': \n",
    "                answer.append(code)\n",
    "\n",
    "            if code == 'sharing intention': \n",
    "                sharing_intention.append(code)\n",
    "\n",
    "            if code == 'disagree': \n",
    "                disagree.append(code)\n",
    "\n",
    "            if code == 'humour or taunting': \n",
    "                humour_taunting.append(code)\n",
    "\n",
    "            if code == 'frustration': \n",
    "                frustration.append(code)\n",
    "\n",
    "            if code == 'apologies': \n",
    "                apologies_remorse.append(code)\n",
    "\n",
    "            if code == 'non-task related': \n",
    "                non_task.append(code)\n",
    "\n",
    "            if code == 'agree or acknowledge': \n",
    "                agree_acknowledge.append(code)\n",
    "\n",
    "            if code == 'opinion or analysis': \n",
    "                opinion_analysis.append(code)\n",
    "\n",
    "            if code == 'encouragement': \n",
    "                encouragement.append(code)\n",
    "\n",
    "            if code == 'emotional expression': \n",
    "                emotional_expression.append(code)\n",
    "\n",
    "            if code == 'thanks or welcome': \n",
    "                thanks_welcome.append(code)\n",
    "\n",
    "\n",
    "            commands_each_minute.append(len(command))\n",
    "            suggestions_each_minute.append(len(suggestion))\n",
    "            opinions_each_minute.append(len(opinion_analysis))\n",
    "            observations_each_minute.append(len(observation))\n",
    "            questions_each_minute.append(len(question))\n",
    "            answers_each_minute.append(len(answer))\n",
    "            agrees_each_minute.append(len(agree_acknowledge))\n",
    "            disagrees_each_minute.append(len(disagree))\n",
    "            sharings_each_minute.append(len(sharing_intention))\n",
    "            emotions_each_minute.append(len(emotional_expression))\n",
    "            encourages_each_minute.append(len(encouragement))\n",
    "            nontasks_each_minute.append(len(non_task))\n",
    "            frustrations_each_minute.append(len(frustration))\n",
    "            humours_each_minute.append(len(humour_taunting))\n",
    "            apologies_each_minute.append(len(apologies_remorse))\n",
    "            thanks_each_minute.append(len(thanks_welcome))\n",
    "            miscs_each_minute.append(len(misc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
