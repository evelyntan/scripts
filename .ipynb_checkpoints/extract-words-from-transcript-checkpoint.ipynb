{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a647f5e-43ac-49ae-9428-88eb8d9f3590",
   "metadata": {},
   "source": [
    "# This script extracts words from the csv \n",
    "## to be used to calculate: \n",
    "- words per minute\n",
    "- total words\n",
    "- variance of words across match \n",
    "- variance of words across speakers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17caad44-95ca-4454-ba84-e4c8bcee3cc6",
   "metadata": {},
   "source": [
    "### *function to get cleaned words list per transcript and count the number of words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e157a-25ec-4ef9-8b72-5841b9a48800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cleaned_words_list(transcript):\n",
    "    import pandas as pd\n",
    "\n",
    "    # import transcript of interest\n",
    "    coded_transcripts_df = pd.read_csv(transcript)\n",
    "\n",
    "    # locate the columns for sentences and players\n",
    "    coded_transcripts_df['Sentence'] = coded_transcripts_df['Sentence'].astype(str)\n",
    "    all_sentences_column = coded_transcripts_df.iloc[:, 3]\n",
    "    players_column = coded_transcripts_df.iloc[:, 0]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_sentences = list(all_sentences_column.values) \n",
    "    players = list(players_column.values)\n",
    "    \n",
    "    # create an empty list to hold all words\n",
    "    all_words = []\n",
    "\n",
    "    # got through each sentence \n",
    "    for sentence in all_sentences:\n",
    "        #print(sentence)\n",
    "        split_the_sentence = sentence.split()\n",
    "\n",
    "        # from each sentence, extract the word\n",
    "        for word in split_the_sentence:\n",
    "            all_words.append(word)\n",
    "\n",
    "    # take out all the '(inaudible)' lines\n",
    "\n",
    "    cleaned_word_list = []\n",
    "\n",
    "    list_with_inaudible_words = [\"(inaudible)\", \"(inaduible\", \"cross\", \"talk)\", \"like\"]\n",
    "    for word in all_words: \n",
    "        if word in list_with_inaudible_words :\n",
    "            continue\n",
    "        else: \n",
    "            cleaned_word_list.append(word)\n",
    "\n",
    "    #print(cleaned_word_list)\n",
    "    \n",
    "    return cleaned_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312fe62-b08e-4e62-874a-fbfcfee13048",
   "metadata": {},
   "source": [
    "### *function to get team number*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84594f0f-20e8-4489-abd5-c1a410368f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_number_from_csv(transcript):\n",
    "\n",
    "    split_file_name_into_content = transcript.split(\"\\\\\")\n",
    "    #print(split_file_name_into_content)\n",
    "    team_number_file_name = split_file_name_into_content[6][:-4]\n",
    "    #print(team_number_file_name)\n",
    "    split = team_number_file_name.split(\"-\")\n",
    "\n",
    "    team_number = split[1]\n",
    "   \n",
    "    return team_number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418e578-6fc1-4f49-ab3c-aa7fb24924c3",
   "metadata": {},
   "source": [
    "### *import the team log csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23786ecf-10de-4683-8121-2cc7d75f7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log_of_team_data_df = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\log-of-team-data.csv')\n",
    "log_of_team_data_df.head()\n",
    "print(log_of_team_data_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c0618-f704-4865-8016-8d145ca5e8b0",
   "metadata": {},
   "source": [
    "### *run the functions over all the cleaned transcripts and merge output with team log*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d373e-7aff-4a5c-a844-6a6e41fa2098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# go through the files in the directory\n",
    "transcripts = glob.glob(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\*.csv')\n",
    "\n",
    "\n",
    "#print('Files in folder:',transcripts)\n",
    "#print(\"\")\n",
    "team_num_and_total_words_dict = {'team_number': [], 'total_words': []}\n",
    "\n",
    "# loop over each transcript\n",
    "for transcript in transcripts: \n",
    "    #print(transcript)\n",
    "    \n",
    "    # get the cleaned words list\n",
    "    cleaned_words = get_cleaned_words_list(transcript)\n",
    "    \n",
    "    # count the total number of cleaned words\n",
    "    total_cleaned_words = len(cleaned_words)\n",
    "    \n",
    "    # add the total number of cleaned words to the dictionary\n",
    "    team_num_and_total_words_dict['total_words'].append(total_cleaned_words)\n",
    "    \n",
    "    # then get the corresponding team number\n",
    "    team_number = get_team_number_from_csv(transcript)\n",
    "    #print(team_number)\n",
    "    \n",
    "    # and add the corresponding team number to the dictionary\n",
    "    team_num_and_total_words_dict['team_number'].append(int(team_number))\n",
    "\n",
    "\n",
    "    print('total words = ', total_cleaned_words)\n",
    "    print(\"\")\n",
    "\n",
    "team_num_and_total_words_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28eeb28-d49c-46f7-95e0-e032fd287053",
   "metadata": {},
   "source": [
    "convert dictionary with team number and total words to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbbd15-344c-4e2f-9c8b-6efba31f0d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the dictionary to dataframe\n",
    "team_num_and_total_words_df = pd.DataFrame.from_dict(team_num_and_total_words_dict)\n",
    "\n",
    "team_num_and_total_words_df\n",
    "#print(team_num_and_total_words_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61841c-1a99-4d53-be21-22e33d6d85fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the dataframes on the team_number column \n",
    "merged_df = pd.merge(log_of_team_data_df, team_num_and_total_words_df, on = 'team_number')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544213e-a344-4060-9465-5e0ffa8b800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd32c69-67f7-4f03-b7db-dba0b42230e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3589f229-1c9c-41c6-8a64-1184ced10c99",
   "metadata": {},
   "source": [
    "## this block converts minutes and seconds to seconds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11833b64-1f63-493f-ab61-e4c5ff09ca49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# convert match duration from minutes and seconds to seconds\n",
    "from datetime import timedelta\n",
    "\n",
    "def seconder(x):\n",
    "    mins, secs = map(float, x.split(':'))\n",
    "    td = timedelta(minutes=mins, seconds=secs)\n",
    "    return td.total_seconds()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0aefc68-edda-4ad5-a9b8-e8a19c2a6846",
   "metadata": {},
   "source": [
    "def get_minute_index(df_of_transcript):\n",
    "    # ensure timestamp as date time\n",
    "    transcript['Timestamp'] = transcript['Timestamp'].apply(seconder)\n",
    "    \n",
    "    # get minute index for match duration:\n",
    "\n",
    "    # first convert timestamp to int\n",
    "    transcript['minute_index'] = transcript['Timestamp'].astype(int)\n",
    "\n",
    "    # turn the timestamp into datetime object\n",
    "    transcript['time_object'] = pd.to_datetime(transcript['minute_index'], unit = 's')\n",
    "\n",
    "    # get only the minutes from the datetime object\n",
    "    transcript['minute_index'] = transcript['time_object'].dt.minute\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c307b-7acc-404c-9a88-9cfd97ac96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minute_index(transcript):\n",
    "    # get a correctly formatted timeobject (ignore date output)\n",
    "    transcript['time_object'] = pd.to_datetime(transcript['Timestamp'], format = '%M:%S:%f')\n",
    "\n",
    "    # get only the minutes from the datetime object\n",
    "    transcript['minute_index'] = transcript['time_object'].dt.minute\n",
    "    \n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e58f8-a393-4b3c-b23e-2626be83d6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "transcript = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\team-22.csv')\n",
    "transcript.head()\n",
    "\n",
    "get_minute_index(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7c4df-be5b-48ba-8180-a2b5cb065dd2",
   "metadata": {},
   "source": [
    "## Function to extract single words for wpm calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1ef2c-d53a-431c-a45c-de3036a114b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cleaned_words(coded_transcripts_df):\n",
    "\n",
    "    # locate the columns for sentences and players\n",
    "    all_sentences_column = coded_transcripts_df.iloc[:, 3]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_sentences = list(all_sentences_column.values) \n",
    "    \n",
    "    # create an empty list to hold all words\n",
    "    all_words = []\n",
    "\n",
    "    # got through each sentence \n",
    "    for sentence in all_sentences:\n",
    "        split_the_sentence = sentence.split()\n",
    "\n",
    "        # from each sentence, extract the word\n",
    "        for word in split_the_sentence:\n",
    "            all_words.append(word)\n",
    "\n",
    "    # take out all the '(inaudible)' lines\n",
    "\n",
    "    cleaned_word_list = []\n",
    "\n",
    "    list_with_inaudible_words = [\"(inaudible)\", \"(inaduible\", \"cross\", \"talk)\", \"like\"]\n",
    "    for word in all_words: \n",
    "        if word in list_with_inaudible_words :\n",
    "            continue\n",
    "        else: \n",
    "            cleaned_word_list.append(word)\n",
    "\n",
    "    #print(cleaned_word_list)\n",
    "    \n",
    "    return len(cleaned_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7f811-4c52-4001-816f-5983bcd0e09b",
   "metadata": {},
   "source": [
    "## Function to get word utterances each minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d59c7f-c013-47ae-9c75-723549e11ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_words_each_minute(transcript):\n",
    "    # get unique minute indexes\n",
    "    # for each row of that minute index, get the number of words\n",
    "    # that's the number of words per minute\n",
    "\n",
    "    unique_minutes =  pd.unique(transcript['minute_index'])\n",
    "\n",
    "    words_each_minute = []\n",
    "\n",
    "    for minute in range(max(unique_minutes) + 1):\n",
    "        sentences_this_minute = transcript[transcript['minute_index'] == minute]\n",
    "\n",
    "        number_of_words_in_minute_index = extract_cleaned_words(sentences_this_minute)\n",
    "\n",
    "        words_each_minute.append(number_of_words_in_minute_index)\n",
    "\n",
    "\n",
    "    #print(\"unique minutes: \", unique_minutes)\n",
    "\n",
    "    #print('words each minute:', words_each_minute)\n",
    "\n",
    "    # returns a list of total word utterance each minute\n",
    "    return words_each_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50213fb-1aea-4fb4-b0b0-05635db4d1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## category utterance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266d646-612a-4f30-a8cc-0b318bf269bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478bdcd-e0bb-4e09-9cd2-55d7619605a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "transcript = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\team-22.csv')\n",
    "\n",
    "transcript = get_minute_index(transcript)\n",
    "\n",
    "get_code_utterance_each_minute(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96b987-ae75-4a72-82cf-c078f7f1da08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# navigate to the category column\n",
    "code_column = transcript.iloc[:, 8]\n",
    "\n",
    "# extract the content of each column into a list\n",
    "all_codes = list(code_column.values) \n",
    "\n",
    "unique_minutes =  pd.unique(transcript['minute_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442ebe9-0423-4c09-b70e-21e4c12242dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an empty list to hold all codes\n",
    "opinion_analysis = []\n",
    "\n",
    "# splitting the dataframe into sub dataframes based on minute index\n",
    "for minute in range(max(unique_minutes) + 1):\n",
    "    codes_this_minute = transcript[transcript['minute_index'] == minute]\n",
    "    \n",
    "    for code in codes_this_minute['rater1_1']:\n",
    "        if code == 'opinion or analysis': \n",
    "            opinion_analysis.append(code)\n",
    "\n",
    "print(opinion_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571668f-632f-4403-ac14-6771f568ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the category column\n",
    "    code_column = transcript.iloc[:, 8]\n",
    "\n",
    "    # extract the content of each column into a list\n",
    "    all_codes = list(code_column.values) \n",
    "\n",
    "    unique_minutes =  pd.unique(transcript['minute_index'])\n",
    "\n",
    "    # create empty lists to hold counts of each category per minute\n",
    "    commands_each_minute = []\n",
    "    suggestions_each_minute = []\n",
    "    opinions_each_minute = []\n",
    "    observations_each_minute = []\n",
    "    questions_each_minute = []\n",
    "    answers_each_minute = []\n",
    "    agrees_each_minute = []\n",
    "    disagrees_each_minute = []\n",
    "    sharings_each_minute = []\n",
    "    emotions_each_minute = []\n",
    "    encourages_each_minute = []\n",
    "    nontasks_each_minute = []\n",
    "    frustrations_each_minute = []\n",
    "    humours_each_minute = []\n",
    "    apologies_each_minute = []\n",
    "    thanks_each_minute = []\n",
    "    miscs_each_minute = []\n",
    "    \n",
    "    # create an empty list to hold all codes\n",
    "    command = []\n",
    "    suggestion = []\n",
    "    opinion_analysis = []\n",
    "    observation = []\n",
    "    question = []\n",
    "    answer = []\n",
    "    agree_acknowledge = []\n",
    "    disagree = []\n",
    "    sharing_intention = []\n",
    "    emotional_expression = []\n",
    "    encouragement = []\n",
    "    non_task = []\n",
    "    frustration = []\n",
    "    humour_taunting = []\n",
    "    apologies_remorse = []\n",
    "    thanks_welcome = []\n",
    "    misc = []\n",
    "\n",
    "    # extract the category counts per minute\n",
    "\n",
    "    for minute in range(max(unique_minutes) + 1):\n",
    "        codes_this_minute = transcript[transcript['minute_index'] == minute]\n",
    "\n",
    "        for code in codes_this_minute['rater1_1']:\n",
    "\n",
    "            if code == 'misc': \n",
    "                misc.append(code)\n",
    "\n",
    "            if code == 'command': \n",
    "                command.append(code)\n",
    "\n",
    "            if code == 'observation': \n",
    "                observation.append(code)\n",
    "\n",
    "            if code == 'suggestion': \n",
    "                suggestion.append(code)\n",
    "\n",
    "            if code == 'question or inquiry': \n",
    "                question.append(code)\n",
    "\n",
    "            if code == 'answer': \n",
    "                answer.append(code)\n",
    "\n",
    "            if code == 'sharing intention': \n",
    "                sharing_intention.append(code)\n",
    "\n",
    "            if code == 'disagree': \n",
    "                disagree.append(code)\n",
    "\n",
    "            if code == 'humour or taunting': \n",
    "                humour_taunting.append(code)\n",
    "\n",
    "            if code == 'frustration': \n",
    "                frustration.append(code)\n",
    "\n",
    "            if code == 'apologies': \n",
    "                apologies_remorse.append(code)\n",
    "\n",
    "            if code == 'non-task related': \n",
    "                non_task.append(code)\n",
    "\n",
    "            if code == 'agree or acknowledge': \n",
    "                agree_acknowledge.append(code)\n",
    "\n",
    "            if code == 'opinion or analysis': \n",
    "                opinion_analysis.append(code)\n",
    "\n",
    "            if code == 'encouragement': \n",
    "                encouragement.append(code)\n",
    "\n",
    "            if code == 'emotional expression': \n",
    "                emotional_expression.append(code)\n",
    "\n",
    "            if code == 'thanks or welcome': \n",
    "                thanks_welcome.append(code)\n",
    "\n",
    "\n",
    "            commands_each_minute.append(len(command))\n",
    "            suggestions_each_minute.append(len(suggestion))\n",
    "            opinions_each_minute.append(len(opinion_analysis))\n",
    "            observations_each_minute.append(len(observation))\n",
    "            questions_each_minute.append(len(question))\n",
    "            answers_each_minute.append(len(answer))\n",
    "            agrees_each_minute.append(len(agree_acknowledge))\n",
    "            disagrees_each_minute.append(len(disagree))\n",
    "            sharings_each_minute.append(len(sharing_intention))\n",
    "            emotions_each_minute.append(len(emotional_expression))\n",
    "            encourages_each_minute.append(len(encouragement))\n",
    "            nontasks_each_minute.append(len(non_task))\n",
    "            frustrations_each_minute.append(len(frustration))\n",
    "            humours_each_minute.append(len(humour_taunting))\n",
    "            apologies_each_minute.append(len(apologies_remorse))\n",
    "            thanks_each_minute.append(len(thanks_welcome))\n",
    "            miscs_each_minute.append(len(misc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeef7a1-9344-4671-bca0-3f74ab900856",
   "metadata": {},
   "source": [
    "## Descriptive Analysis Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8fdad-dc39-4b5f-a042-56ec662726f4",
   "metadata": {},
   "source": [
    "this function gets the descriptive stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3eeb15-a5ec-4e2d-91f1-e1d34b9b275e",
   "metadata": {},
   "source": [
    "Within team variables: \n",
    " - mean wpm : rate of chat\n",
    " - variance wpm : distribution of chat across match duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a28cb6-1f5a-4eb9-b4a5-6f255e794eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_descriptive_stats_for_words(count_of_words_each_minute):\n",
    "    # get descriptive stats\n",
    "\n",
    "    # get the stats and add stats as element to list\n",
    "    get_mean_wpm = np.mean(count_of_words_each_minute)\n",
    "    \n",
    "    get_variance_wpm = np.var(count_of_words_each_minute)\n",
    "    \n",
    "    get_sum_wpm = np.sum(count_of_words_each_minute)\n",
    "\n",
    "    get_median_wpm = np.median(count_of_words_each_minute)\n",
    "\n",
    "    #print('mean:', mean_wpm)\n",
    "    #print('variance:', variance_wpm)\n",
    "    #print('sum:', sum_wpm)\n",
    "    #print('median:', median_wpm)\n",
    "    \n",
    "    return get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1a6da-e31d-4f4f-9b2c-fd8f9ff722c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ad840-bc72-49f2-8404-282d762ff118",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRYING TO RUN IT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4082c97f-a886-441e-b092-ee485767af28",
   "metadata": {
    "tags": []
   },
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "transcript = pd.read_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\team-22.csv')\n",
    "\n",
    "# first convert to minute index\n",
    "get_minute_index(transcript)\n",
    "\n",
    "# get word utterance each minute\n",
    "words_each_minute = get_words_each_minute(transcript)\n",
    "\n",
    "# then get the code utterance each minute\n",
    "#get_code_utterance_each_minute(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33c1cb57-21f7-4617-8b63-1bff1b558df0",
   "metadata": {},
   "source": [
    "# populate the descriptives\n",
    "team_number = []\n",
    "mean_wpm = []\n",
    "variance_wpm = []\n",
    "sum_wpm = []\n",
    "median_wpm = []\n",
    "\n",
    "# then get descriptives\n",
    "get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm = get_descriptive_stats_for_words(words_each_minute)\n",
    "\n",
    "mean_wpm.append(get_mean_wpm)\n",
    "variance_wpm.append(get_variance_wpm)\n",
    "sum_wpm.append(get_sum_wpm)\n",
    "median_wpm.append(get_median_wpm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd332753-0371-4351-a1b0-26cd0bf75683",
   "metadata": {},
   "source": [
    "print(team_number, mean_wpm, variance_wpm, sum_wpm, median_wpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c3023-d316-4c24-8eff-e32691ad5cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5300a833-c8fd-4b08-aaf0-93b56a1d5120",
   "metadata": {},
   "source": [
    "This section runs all the functions to get descriptive stats for word utterances\n",
    "----------------\n",
    "\n",
    "to do: \n",
    "- merge with the log of team data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cea94e-a45d-4e0e-8689-3a17012d79e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# populate the descriptives\n",
    "team_number = []\n",
    "mean_wpm = []\n",
    "variance_wpm = []\n",
    "sum_words = []\n",
    "median_wpm = []\n",
    "\n",
    "# go through the files in the directory\n",
    "transcripts = glob.glob(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\recoded-transcripts\\*.csv')\n",
    "\n",
    "#get_team_number_from_xls(transcripts)\n",
    "for transcript in transcripts: \n",
    "    print(transcript)\n",
    "\n",
    "    # get team number\n",
    "    team_number.append(int(get_team_number_from_csv(transcript)))\n",
    "    \n",
    "    # read the transcript as a dataframe\n",
    "    transcript = pd.read_csv(transcript)\n",
    "\n",
    "    #transcript.head()\n",
    "\n",
    "    # first convert to minute index\n",
    "    get_minute_index(transcript)\n",
    "\n",
    "    # then get the word utterance each minute\n",
    "    words_each_minute = get_words_each_minute(transcript)\n",
    "\n",
    "    # then get descriptives\n",
    "    get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm = get_descriptive_stats_for_words(words_each_minute)\n",
    "\n",
    "    mean_wpm.append(get_mean_wpm)\n",
    "    variance_wpm.append(get_variance_wpm)\n",
    "    sum_words.append(get_sum_wpm)\n",
    "    median_wpm.append(get_median_wpm)\n",
    "\n",
    "print(team_number, mean_wpm, variance_wpm, sum_words, median_wpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104298f-5f4c-4e92-a009-e94ff9367194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050253bd-6748-48ed-b247-a3ae40869737",
   "metadata": {},
   "source": [
    "create a dataframe of descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8e87e-27e7-4844-99f6-becc41eff429",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives = {'team_number': team_number, 'mean_wpm': mean_wpm, 'variance_wpm': variance_wpm, 'sum_words': sum_words, 'median_wpm': median_wpm}\n",
    "\n",
    "descriptives_df = pd.DataFrame(descriptives)\n",
    "\n",
    "descriptives_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a47d878-4c9b-4de7-8901-c36f01debc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84350f89-2116-4401-a83e-d2c101faf6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the dataframes on the team_number column \n",
    "log_with_descriptives = pd.merge(log_of_team_data_df, descriptives_df, on = 'team_number')\n",
    "\n",
    "log_with_descriptives\n",
    "\n",
    "# uncomment to save to csv\n",
    "#log_with_descriptives.to_csv(r'D:\\Projects\\UG-league-project\\data\\coded-transcripts\\log_with_descriptives.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853cf2c1-c225-4702-b147-502d98176b29",
   "metadata": {},
   "source": [
    "## This section gets descriptive stats for code utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60058784-ba0a-49c3-b350-28f68e343b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptives to populate\n",
    "\n",
    "team_number = []\n",
    "\n",
    "# opinions/analysis\n",
    "opinion_mean_upm = []\n",
    "opinion_variance_upm = []\n",
    "opinion_sum = []\n",
    "opinion_median_upm = []\n",
    "\n",
    "# observations\n",
    "obs_mean_upm = []\n",
    "obs_variance_upm = []\n",
    "obs_sum = []\n",
    "obs_median_upm = []\n",
    "\n",
    "# commands\n",
    "command_mean_upm = []\n",
    "command_variance_upm = []\n",
    "command_sum = []\n",
    "command_median_upm = []\n",
    "\n",
    "# suggestions\n",
    "suggest_mean_upm = []\n",
    "suggest_variance_upm = []\n",
    "suggest_sum = []\n",
    "suggest_median_upm = []\n",
    "\n",
    "# thanks\n",
    "thanks_mean_upm = []\n",
    "thanks_variance_upm = []\n",
    "thanks_sum = []\n",
    "thanks_median_upm = []\n",
    "\n",
    "# sharing intentions\n",
    "intentions_mean_upm = []\n",
    "intentions_variance_upm = []\n",
    "intentions_sum = []\n",
    "intentions_median_upm = []\n",
    "\n",
    "# questions/inquirys\n",
    "questions_mean_upm = []\n",
    "questions_variance_upm = []\n",
    "questions_sum = []\n",
    "questions_median_upm = []\n",
    "\n",
    "# answers\n",
    "answers_mean_upm = []\n",
    "answers_variance_upm = []\n",
    "answers_sum = []\n",
    "answers_median_upm = []\n",
    "\n",
    "# emotional expressions\n",
    "emotionex_mean_upm = []\n",
    "emotionex_variance_upm = []\n",
    "emotionex_sum = []\n",
    "emotionex_median_upm = []\n",
    "\n",
    "# agrees/acknowledge\n",
    "agree_mean_upm = []\n",
    "agree_variance_upm = []\n",
    "agree_sum = []\n",
    "agree_median_upm = []\n",
    "\n",
    "# humour/taunting\n",
    "humour_mean_upm = []\n",
    "humour_variance_upm = []\n",
    "humour_sum = []\n",
    "humour_median_upm = []\n",
    "\n",
    "# apologies\n",
    "apology_mean_upm = []\n",
    "apology_variance_upm = []\n",
    "apology_sum = []\n",
    "apology_median_upm = []\n",
    "\n",
    "# encouragements\n",
    "encourage_mean_upm = []\n",
    "encourage_variance_upm = []\n",
    "encourage_sum = []\n",
    "encourage_median_upm = []\n",
    "\n",
    "# frustrations\n",
    "frust_mean_upm = []\n",
    "frust_variance_upm = []\n",
    "frust_sum = []\n",
    "frust_median_upm = []\n",
    "\n",
    "# disagrees\n",
    "disagree_mean_upm = []\n",
    "disagree_variance_upm = []\n",
    "disagree_sum = []\n",
    "disagree_median_upm = []\n",
    "\n",
    "# non-task \n",
    "nontask_mean_upm = []\n",
    "nontask_variance_upm = []\n",
    "nontask_sum = []\n",
    "nontask_median_upm = []\n",
    "\n",
    "# misc\n",
    "misc_mean_upm = []\n",
    "misc_variance_upm = []\n",
    "misc_sum = []\n",
    "misc_median_upm = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4244fc3-5943-4349-9f96-3f0828428e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opinions\n",
    "# then get descriptives\n",
    "get_mean_wpm, get_variance_wpm, get_sum_wpm, get_median_wpm = get_descriptive_stats_for_words(words_each_minute)\n",
    "\n",
    "# append to corresponding list\n",
    "opinion_mean_upm = []\n",
    "opinion_variance_upm = []\n",
    "opinion_sum = []\n",
    "opinion_median_upm = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78438ca3-4238-42a2-8c4f-019bcf5e8eaa",
   "metadata": {},
   "source": [
    "### to do: \n",
    "- get speaker distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f338a-47e9-4ad2-813b-ee7c5f38fedc",
   "metadata": {},
   "source": [
    "get speaker distribution\n",
    "- step 1: get total words per player per team\n",
    "- step 2: calculate variance of words per player per team"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49a78656-13f9-4dfb-a807-879d168e10de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a769356a-e558-4d1a-a69c-e52c203b9403",
   "metadata": {},
   "source": [
    "######### Cells in this section are to remind you of the steps you took to create the function ##########"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71ca34f9-5906-4aea-ae5c-dc3104aec0ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# create an empty list to hold all words\n",
    "all_words = []\n",
    "\n",
    "# got through each sentence \n",
    "for sentence in all_sentences:\n",
    "    split_the_sentence = sentence.split()\n",
    "    \n",
    "    # from each sentence, extract the word\n",
    "    for word in split_the_sentence:\n",
    "        all_words.append(word)\n",
    "\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6e8a686-b0a4-47e0-a458-be5c6511fc65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# take out all the '(inaudible)' lines\n",
    "\n",
    "cleaned_word_list = []\n",
    "\n",
    "list_with_inaudible_words = [\"(inaudible)\", \"(inaduible\", \"cross\", \"talk)\", \"like\"]\n",
    "for word in all_words: \n",
    "    if word in list_with_inaudible_words :\n",
    "        continue\n",
    "    else: \n",
    "        cleaned_word_list.append(word)\n",
    "\n",
    "        \n",
    "print(cleaned_word_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a1e89f8-40ad-4aea-bbe1-5652081817e0",
   "metadata": {},
   "source": [
    "# get mean words per minute per team \n",
    "def mean_words_per_second(merged_df): \n",
    "    pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "    \n",
    "    merged_df['mean_wpm'] = merged_df['total_words']/(merged_df['match_duration_in_seconds']/60)\n",
    "    \n",
    "    return merged_df\n",
    "    # needs to look like: \n",
    "    # total_words/(match_duration_in_seconds / 60)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd46cd33-3719-4955-a1dd-bb95c4889ccc",
   "metadata": {},
   "source": [
    "df_with_mean_wpm = mean_words_per_second(merged_df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2138b78a-9982-4968-8517-9558772ed1e4",
   "metadata": {},
   "source": [
    "######### Cells in this section are to remind you of the steps you took to create the function ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1c014-7f89-4d30-9760-ef91996f1a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
