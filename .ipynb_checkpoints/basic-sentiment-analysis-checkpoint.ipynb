{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee0ec1f-9b0a-4906-b6ab-1e3b7a0f85b5",
   "metadata": {},
   "source": [
    "# Cleaning the transcript using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073c3fc-b82c-4e4c-a191-370aad7ae251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying some NLTK stuff here\n",
    "import nltk\n",
    "nltk.download(['averaged_perceptron_tagger', \n",
    "               'stopwords'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a606a318-b412-4f49-8405-a48bacd5b262",
   "metadata": {},
   "source": [
    "# split sentence into words/utterances\n",
    "tokens = nltk.word_tokenize(full_combined_transcript)\n",
    "\n",
    "#tokens\n",
    "\n",
    "# include only the words that are made up of letters\n",
    "# remove punctuation marks and numbers\n",
    "words_only_list = []\n",
    "for token in tokens: \n",
    "    if token.isalpha():\n",
    "        words_only_list.append(token)\n",
    "        \n",
    "\n",
    "print(\"total words: \", len(words_only_list))\n",
    "words_only_list\n",
    "#tagged = nltk.pos_tag(tokens)\n",
    "#tagged "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d1a5fe8-6d13-476f-af34-b8f18cac9fd5",
   "metadata": {},
   "source": [
    "#from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "filtered_list = []\n",
    "for word in words_only_list:\n",
    "    if word.casefold() not in stop_words: \n",
    "        filtered_list.append(word)\n",
    "        \n",
    "print(\"total words after removing stopwords: \", len(filtered_list))        \n",
    "filtered_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3411f66-6d57-4273-8ac8-95140dc023bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "filtered_list = []\n",
    "# \n",
    "#cleaned_word_list\n",
    "for word in cleaned_words :\n",
    "    if word.casefold() not in stop_words: \n",
    "        filtered_list.append(word)\n",
    "        \n",
    "print(\"total words after removing stopwords: \", len(filtered_list))        \n",
    "filtered_list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc250240-e65c-4148-9db8-816c060c3894",
   "metadata": {},
   "source": [
    "# Creating Frequency Distributions and Analysing Sentiment using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776f255-ba97-4980-8879-e6d9acf14cbb",
   "metadata": {},
   "source": [
    "## Getting Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74b5ec-5d4b-4220-9b2a-acf79e091769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequence distribution of words\n",
    "frequency_distribution_of_filtered_list = nltk.FreqDist(filtered_list)\n",
    "frequency_distribution_of_filtered_list\n",
    "\n",
    "# find most common words\n",
    "# number in bracket indicates the top x number (eg. 5 means the top 5 most frequent words)\n",
    "frequency_distribution_of_filtered_list.most_common(10)\n",
    "\n",
    "# visualise the distribution in a table\n",
    "frequency_distribution_of_filtered_list.tabulate(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7ab24-f610-40a2-ab91-fbe91e11ea3f",
   "metadata": {},
   "source": [
    "## Extracting Concordance and Collocations\n",
    "In the context of NLP, a concordance is a collection of word locations along with their context. You can use concordances to find:\n",
    "\n",
    "    How many times a word appears\n",
    "    Where each occurrence appears\n",
    "    What words surround each occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c5c14-b371-4075-abb5-4711aba909c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find what the context surrounding a word is\n",
    "full_text_including_stopwords_and_punctuations = nltk.Text(cleaned_word_list)\n",
    "\n",
    "# set word of interest in \"\" in brackets\n",
    "full_text_including_stopwords_and_punctuations.concordance(\"go\", lines = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98949e2-7854-49ad-88e3-0230d29c5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding collocations (sequences)\n",
    "\n",
    "#step 1 define the number of ngrams the finder is looking for\n",
    "bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(cleaned_word_list)\n",
    "trigram_finder = nltk.collocations.TrigramCollocationFinder.from_words(cleaned_word_list)\n",
    "\n",
    "# find the top 5 (the number in the bracket) most common bi grams\n",
    "print(\"top 10 most common bigrams: \")\n",
    "print(bigram_finder.ngram_fd.most_common(10))\n",
    "print(\"\")\n",
    "\n",
    "print(\"top 10 most common trigrams: \")\n",
    "print(trigram_finder.ngram_fd.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684e178-e124-428c-a19b-c730c09cab15",
   "metadata": {},
   "source": [
    "## trying to do sentiment analysis with built in nltk model VADER \n",
    "-note: model is best suited for short texts like tweets and social media things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fec122-15c1-4083-bc83-54474ba8fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# create a string of words \n",
    "string_of_cleaned_word_list = \" \".join(cleaned_word_list)\n",
    "# string_of_cleaned_word_list\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(string_of_cleaned_word_list)\n",
    "\n",
    "# team 6 (low cohesion, mean = 2.67, 3 person team, lost) results: {'neg': 0.121, 'neu': 0.655, 'pos': 0.224, 'compound': 0.9999}\n",
    "# team 32 (high cohesion, mean = 6.83, 3 person team, won ) results: {'neg': 0.141, 'neu': 0.666, 'pos': 0.193, 'compound': 0.9996}\n",
    "# team 46 (mid cohesion, mean = 4.44, 3 person team, lost) results: {'neg': 0.152, 'neu': 0.687, 'pos': 0.161, 'compound': -0.7709}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
